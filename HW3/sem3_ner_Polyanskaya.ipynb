{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 3  NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:\n",
    "\n",
    "Реализуйте 2 функции препроцессинга:\n",
    "\n",
    "- Удалить именованные сущности с помощью natasha (https://github.com/natasha/yargy)\n",
    "- Удалить именованные сущности с помощью deepmipt (https://github.com/deepmipt/ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = '''Добрый день!\n",
    "\n",
    "Пожалуйста, уточните, на данный момент для посещения Камчатки требуется ли предоставление отрицательных тестов на COVID19 или какие-либо другие документов, помимо паспорта гражданина РФ для прибывающих из Москвы регулярным рейсом?\n",
    "\n",
    "Нужно ли оформлять какие-либо пропуски для пребывания на тер-рии Камчатки? Целью поездки явлеятся туризм, проживание заранее оплачивается, экскурсионные услуги будут организованы непосредственно через отель. Есть ли другие ограничения или меры, о которых необходимо знать туристам, которые отправляются на Камчатку (11-16 августа)\n",
    "\n",
    "\n",
    "Заранее спасибо\n",
    "\n",
    "Елена Мягкова\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsNERTagger,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "ner_tagger = NewsNERTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from razdel import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words(\"russian\")\n",
    "stops.extend(['здравствуйте', 'добрый', 'день'])\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "def tokenizer(text_data):\n",
    "    tokens = [_.text for _ in list(tokenize(str(text_data).lower())) if not re.search('[^а-яА-ЯёЁa-zA-z]', _.text)]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_natasha(text: str) -> str:\n",
    "    #text = text.replace('\\n', ' ')\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    for span in doc.spans:\n",
    "        text = text.replace(span.text, \"\")\n",
    "    new_text = re.sub(\"\\s+\", \" \", text)\n",
    "    \n",
    "    return re.sub(r\"([^\\w\\s])\", r\" \\1 \", new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Добрый день !  Пожалуйста ,  уточните ,  на данный момент для посещения требуется ли предоставление отрицательных тестов на COVID19 или какие - либо другие документов ,  помимо паспорта гражданина для прибывающих из регулярным рейсом ?  Нужно ли оформлять какие - либо пропуски для пребывания на тер - рии  ?  Целью поездки явлеятся туризм ,  проживание заранее оплачивается ,  экскурсионные услуги будут организованы непосредственно через отель .  Есть ли другие ограничения или меры ,  о которых необходимо знать туристам ,  которые отправляются на  ( 11 - 16 августа )  Заранее спасибо '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_with_natasha(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-28 21:34:20.70 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz download because of matching hashes\n",
      "2020-09-28 21:34:22.247 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_rus_bert_v1.tar.gz download because of matching hashes\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0928 21:34:27.431642 13776 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bert_dp\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "2020-09-28 21:34:27.724 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from C:\\Users\\User\\.deeppavlov\\models\\ner_rus_bert\\tag.dict]\n",
      "I0928 21:34:27.724770 13776 simple_vocab.py:112] [loading vocabulary from C:\\Users\\User\\.deeppavlov\\models\\ner_rus_bert\\tag.dict]\n",
      "W0928 21:34:27.751733 13776 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0928 21:34:27.753730 13776 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py:223: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0928 21:34:27.754727 13776 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py:223: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Using TensorFlow backend.\n",
      "W0928 21:34:27.947865 13776 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py:194: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0928 21:34:27.965568 13776 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\deeppavlov\\models\\bert\\bert_ner.py:126: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0928 21:34:27.982522 13776 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\deeppavlov\\models\\bert\\bert_ner.py:227: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0928 21:34:28.011453 13776 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bert_dp\\modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0928 21:34:29.666826 13776 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0928 21:34:29.685826 13776 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bert_dp\\modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0928 21:34:29.721693 13776 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bert_dp\\modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0928 21:34:31.589650 13776 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0928 21:34:31.660395 13776 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\deeppavlov\\models\\bert\\bert_ner.py:350: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0928 21:34:31.810236 13776 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\crf\\python\\ops\\crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0928 21:34:37.941166 13776 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0928 21:34:53.254851 13776 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\deeppavlov\\models\\bert\\bert_ner.py:139: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2020-09-28 21:34:53.452 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from C:\\Users\\User\\.deeppavlov\\models\\ner_rus_bert\\model]\n",
      "I0928 21:34:53.452349 13776 tf_model.py:52] [loading model from C:\\Users\\User\\.deeppavlov\\models\\ner_rus_bert\\model]\n",
      "W0928 21:34:53.560083 13776 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py:55: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import configs, build_model\n",
    "\n",
    "ner_model = build_model(configs.ner.ner_rus_bert, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_deepmipt(text: str) -> str:\n",
    "    new_text = []\n",
    "    res = ner_model([text])\n",
    "    for token, entity in zip(res[0][0], res[1][0]):\n",
    "        if entity == \"O\":\n",
    "            new_text.append(token)\n",
    "    return re.sub(r\"\\s+\", \" \", ' '.join(new_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Добрый день ! Пожалуйста , уточните , на данный момент для посещения требуется ли предоставление отрицательных тестов на COVID19 или какие - либо другие документов , помимо паспорта гражданина для прибывающих из регулярным рейсом ? Нужно ли оформлять какие - либо пропуски для пребывания на тер - рии ? Целью поездки явлеятся туризм , проживание заранее оплачивается , экскурсионные услуги будут организованы непосредственно через отель . Есть ли другие ограничения или меры , о которых необходимо знать туристам , которые отправляются на ( 11 - 16 августа ) Заранее спасибо '"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_with_deepmipt(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "На предыдущем занятии вы реализовывали функции поиска ближайших ответов на запросы через TF-IDF и BM25. \n",
    "Сравните качество нахождения верного ответа для обоих методов в трех случаях:\n",
    "- с функцией ```preprocess_with_natasha```\n",
    "- с функцией ```preprocess_with_deepmipt```\n",
    "- без препроцессинга\n",
    "\n",
    "Для измерения качества используйте метрику accuracy. Считаем, что ответ верный, если он входит в топ-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовлю данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>У ребенка в школе продлили каникулы. Могу ли я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>Больничный лист?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>Есть ли компенсация, в случае если есть разниц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>как оплачивается больничный при коронавирусе?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>Я контактный, дадут ли больничный?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           question\n",
       "0     57  У ребенка в школе продлили каникулы. Могу ли я...\n",
       "1     57                                   Больничный лист?\n",
       "2     57  Есть ли компенсация, в случае если есть разниц...\n",
       "3     57      как оплачивается больничный при коронавирусе?\n",
       "4     57                 Я контактный, дадут ли больничный?"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_data = pd.read_excel(\"answers_base.xlsx\")\n",
    "\n",
    "question_index = {}\n",
    "for question_chunk, answer_n in answers_data[[\"Текст вопросов\", \"Номер связки\"]].values:\n",
    "    questions = question_chunk.split('\\n')\n",
    "    for q in questions:\n",
    "        question_index[q] = answer_n\n",
    "            \n",
    "question_df = pd.DataFrame({\"question\": q, \"index\": i} for q,i in question_index.items())\n",
    "question_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираю bm25 в одну функцию от названия колонки в датафрейме с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from math import log\n",
    "\n",
    "def new_tf(count_matrix):\n",
    "    return (count_matrix * (k+1)) / (count_matrix + k * (1 - b + b * (length/avgdl) ))\n",
    "\n",
    "def idf(i):\n",
    "    res = log( (N - n[0, i] + 0.5) / (n[0, i] + 0.5) )\n",
    "    return res\n",
    "\n",
    "def bm25_search(q):\n",
    "    q_vec = count_vectorizer.transform([q]).toarray()\n",
    "    mask = q_vec * idf_vector\n",
    "    res = np.dot(tf_matrix, mask.T)\n",
    "    index = np.argmax(res)\n",
    "    return answers_data[\"Номер связки\"][index]\n",
    "\n",
    "def bm25(data_col):\n",
    "\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    corpora = answers_data[\"Текст ответа\"]\n",
    "    count_matrix = count_vectorizer.fit_transform(corpora)\n",
    "    #count_matrix.shape\n",
    "\n",
    "    k = 2.0\n",
    "    b = 0.75\n",
    "\n",
    "    length = count_matrix.sum(axis=1)\n",
    "    avgdl = length.mean()\n",
    "\n",
    "\n",
    "    tf_matrix = new_tf(count_matrix)\n",
    "    #tf_matrix.shape\n",
    "\n",
    "    n = (tf_matrix != 0).sum(axis=0)\n",
    "    N = count_matrix.shape[0]\n",
    "\n",
    "    idf_vector = np.array([idf(i) for i in range(count_matrix.shape[1])])\n",
    "    #idf_vector.shape\n",
    "    \n",
    "    return question_df[data_col].progress_apply(bm25_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираю TF-IDF в одну функцию от названия колонки в датаврейме с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf(data_col):\n",
    "    vectorizer = TfidfVectorizer(analyzer=str.split)\n",
    "    corpora = answers_data[\"Текст ответа\"]\n",
    "    X = vectorizer.fit_transform(corpora)\n",
    "    #X.shape\n",
    "    \n",
    "    def get_answer(querry):\n",
    "        q_vec = vectorizer.transform([querry]).toarray()\n",
    "        res = np.dot(X.toarray(), q_vec.T)\n",
    "        index = np.argmax(res)\n",
    "        return answers_data[\"Номер связки\"][index]\n",
    "    \n",
    "    return question_df[data_col].progress_apply(get_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаю два препроцессинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c05a86fe2624bc7824bd66633a4c285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=768), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f90596279a94a3598f78d538f1b0b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=768), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_df[\"natasha\"] = question_df[\"question\"].progress_apply(preprocess_with_natasha)\n",
    "question_df[\"deeppavlov\"] = question_df[\"question\"].progress_apply(preprocess_with_deepmipt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаю таблицу для результатов подсчета accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>natasha</th>\n",
       "      <th>deeppavlov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question natasha deeppavlov\n",
       "tf-idf      NaN     NaN        NaN\n",
       "bm25        NaN     NaN        NaN"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\"question\", \"natasha\", \"deeppavlov\"]\n",
    "\n",
    "res_df = pd.DataFrame(index=[\"tf-idf\", \"bm25\"], columns=col_names)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняю все ячейки, применяя два разных поиска к данным с термя разными препроцессингами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc753fc73fe54bf7b9a6e1da7a7ae1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=768), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c8850ae82b449aba011f34ba9ca4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=768), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cd80d2fbd944a5b9691f95f34ab0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=768), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cd9ab164634098808a0a4cf1313afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=768), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95104d40c7954eb58876c145c8d2f09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=768), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d90e397ad840e0a9f71c3512a29bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=768), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col_name in col_names:\n",
    "    question_df[\"pred_\"+col_name+\"_bm25\"] = bm25(col_name)\n",
    "    question_df[\"pred_\"+col_name+\"_tfidf\"] = tfidf(col_name)\n",
    "    \n",
    "    res_df[col_name][\"tf-idf\"] = ((question_df[\"pred_\"+col_name+\"_tfidf\"] == question_df['index']).sum() / len(question_df))\n",
    "    res_df[col_name][\"bm25\"] = ((question_df[\"pred_\"+col_name+\"_bm25\"] == question_df['index']).sum() / len(question_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговые значения accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>natasha</th>\n",
       "      <th>deeppavlov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm25</th>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.329427</td>\n",
       "      <td>0.330729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        question   natasha deeppavlov\n",
       "tf-idf  0.238281  0.291667   0.291667\n",
       "bm25    0.332031  0.329427   0.330729"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 3__:    \n",
    "Улучшить правила в natasha. Написать правила, которые ловят даты в следующих примерах и пересчитать статистику из Задачи 2:\n",
    "- Уехал 8-9 ноября в Сочи\n",
    "- Уезжаю 5 числа                           \n",
    "- 20го сентября заболел\n",
    "\n",
    "Пример можно посмотреть тут: https://github.com/natasha/yargy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
